---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Opening Keynote at the Google AI Summer School, 2020"
subtitle: ""
summary: ""
authors: [Archana Swaminathan]
tags: [Google AI Summer School, Machine Learning, Deep Learning]
categories: [Experiences]
date: 2020-08-20T10:53:53+05:30
lastmod: 2020-08-20T10:53:53+05:30
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

This article has been written from notes I took throughout the Opening Keynote at the Google AI Summer School. The opening keynote was delivered by Jeff Dean, Head of Google AI and moderated by Manish Gupta, Director of Google AI Research, Bangalore.

## Introduction

Jeff Dean is a Senior Fellow at Google and the global head of Google AI. He saved Google at a very critical time and is essential to what contributed to make the Google Search Engine the best and the fastest in the world today. He is currently doing exciting research in the field of explainable AI for problems that the world is facing. He also helped create Tensorflow, the world's most used Machine Learning Library.

## Notes from the Talk:

Deep Learning has revolutionized the way of solving challenging problems. There are over 130 new papers on Machine Learning on Arxiv every day. Deep Learning can be considered a modern reincarnation of Artificial Neural Networks. Key benefits and features of Deep Learning are:

* Availability of new network architectures
* Ability to scale to larger datasets and efficient computation of the math
* Learns features from raw, noisy, heterogenous data
* No explicit feature engineering required

Deep Learning architectures are remarkably flexible with taking in inputs and giving outputs of various forms, some examples are getting a categorical label from a pixel input (image), an audio input translating to a phrase that is a string, and language translation from one language to another.

Deep Learning has also helped us come up with solutions to problems where the computer can achieve better results than a human. One such example is the Imagenet challenge, that Stanford conducts every year that classifies images into classes.

* In 2011, the winner of the challenge was able to achieve 26% error, where humans were able to do the same task with 5% error.
* In 2012, Geoffrey Hinton and his team used Deep Learning for the very first time in this challenge, and was the pioneer of bringing deep convolutional networks for the image classification task. Following his attempt, Deep Learning became very popular in further editions of the challenge.
* In 2017, the winner of the challenge was able to achieve 3% error on the Imagenet dataset, finally beating the human error of 5%.


